/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
[2025-02-17 17:54:15,489] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.91s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:09,  4.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:19<00:07,  7.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.98s/it]
Some weights of the model checkpoint at microsoft/llava-med-v1.5-mistral-7b were not used when initializing LlavaMistralForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight']
- This IS expected if you are initializing LlavaMistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaMistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/modeling_utils.py:519: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location=map_location)
/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/home/r11kaijun/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:421: UserWarning: `num_beams` is set to None - defaulting to 1.
  warnings.warn("`num_beams` is set to None - defaulting to 1.", UserWarning)
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
Loading LoRA weights from ../checkpoints/train_5k_quantized_4-epoch-3-lr-2e5
Merging weights
Convert to FP16...
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17096560/s50056854/92846817-78ec0a2e-50265c40-0e7cad3b-6d912f6e.jpg
study_id 50056854 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17096560/s50056854/92846817-78ec0a2e-50265c40-0e7cad3b-6d912f6e.jpg ground_truth Left-sided subclavian port-a-cath continues to have its tip in the distal svc, near the cavoatrial junction. Heart remains enlarged, which may reflect cardiomegaly, although pericardial effusion should also be considered. Mediastinal contours are unchanged. There is persistent minimal blunting the left costophrenic angle, which may represent a tiny effusion or chronic pleural thickening. Streaky linear opacities at the left base may reflect areas of atelectasis or scarring. No focal airspace consolidation is seen to suggest pneumonia. No pneumothorax. No evidence of pulmonary edema. Linear density overlying the left upper quadrant is likely external to the patient, but clinical correlation would be recommended. prediction The lung volumes are low. The heart size is normal. The hilar and mediastinal contours are normal. The pulmonary vasculature is normal. There is no focal consolidation, pleural effusion or pneumothorax.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17055995/s50058197/77dab00f-4b12bcda-d0dfea2c-e540bb9e-fe5b3114.jpg
study_id 50058197 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17055995/s50058197/77dab00f-4b12bcda-d0dfea2c-e540bb9e-fe5b3114.jpg ground_truth New right ij central venous line with tip likely within the right atrium and could be withdrawn to be in the lower svc. Pulmonary vascular congestion. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17055995/s50152901/55a0e030-4bb997bd-b5d19ede-c9996085-f874501a.jpg
study_id 50152901 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17055995/s50152901/55a0e030-4bb997bd-b5d19ede-c9996085-f874501a.jpg ground_truth Single portable view of the chest. Right picc line is no longer seen. The patient is rotated to the left. The lungs however are clear. Calcified granuloma seen at the right lung base. Cardiomediastinal silhouette is within normal limits. No acute osseous abnormality detected, lower cervical fixation hardware is again seen. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p16/p16306599/s50173042/b3e3432f-8de35a57-84779127-6d36d4db-a8e9317f.jpg
study_id 50173042 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p16/p16306599/s50173042/b3e3432f-8de35a57-84779127-6d36d4db-a8e9317f.jpg ground_truth Single ap upright portable view of the chest was obtained. The right costophrenic angle is not fully included on the image. Given this, no definite focal consolidation is seen. There is left base atelectasis. No large pleural effusion or evidence of pneumothorax is seen. The cardiac silhouette is top normal to mildly enlarged. The aorta is somewhat tortuous. No overt pulmonary edema is seen. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p10/p10649970/s50196128/1d781883-bb2d3cf0-14fd56ff-c4d0e12f-1143d820.jpg
study_id 50196128 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p10/p10649970/s50196128/1d781883-bb2d3cf0-14fd56ff-c4d0e12f-1143d820.jpg ground_truth Ap view of the chest. There are low lung volumes. Calcified nodules in the right lung base are unchanged from prior, likely sequelae of prior healed infection. There is bibasilar atelectasis. No focal consolidation, pleural effusion or pneumothorax. The cardiomediastinal silhouette is unremarkable. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p13/p13970691/s50207397/05a331ae-17b42621-787f72cc-ebadd560-6d2586c0.jpg
study_id 50207397 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p13/p13970691/s50207397/05a331ae-17b42621-787f72cc-ebadd560-6d2586c0.jpg ground_truth Single ap upright portable view of the chest was obtained. There are low lung volumes, which accentuate the bronchovascular markings. Given this, there appears to be mild central vascular pulmonary engorgement. Soft tissue overlying the lung base likely causes underpenetration. The cardiac and mediastinal silhouettes are stable. No definite focal consolidation or pneumothorax is seen. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11717909/s50281684/dec3e055-ebb80e67-6fe65c6e-de8f0130-d39b8896.jpg
study_id 50281684 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11717909/s50281684/dec3e055-ebb80e67-6fe65c6e-de8f0130-d39b8896.jpg ground_truth Right picc line tip is at the level of the right atrium and should be pulled back 3 cm to secure it position at the cavoatrial junction or above. Right basal atelectasis is unchanged associated with minimal amount of pleural effusion. There is no pneumothorax. No pulmonary congestion . prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The patient is status post median sternotomy and cabg.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11717909/s50309094/edd6b83c-688ee075-7706abe7-8585945e-88b5d0c7.jpg
study_id 50309094 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11717909/s50309094/edd6b83c-688ee075-7706abe7-8585945e-88b5d0c7.jpg ground_truth Lungs: continued parenchymal disease is seen in the right chest which has not altered significantly. There is also left basilar disease. Pleura: likely there is a right pleural effusion is well as a small left pleural effusion. Mediastinum: surgical clips noted in the mediastinum heart: the heart is not enlarged. Osseous structures: the osseous structures are normal for age. Additional findings: endotracheal tube is in the region of the thoracic inlet. Left-sided picc line terminates in the satisfactory position. A new right internal jugular catheter terminates in the right atrium. Nasogastric tube some stomach. Monitor leads noted. There is no pneumothorax. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The endotracheal tube terminates 5 cm above the carina. The nasogastric tube terminates in the stomach.
image_url: The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
/home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p18/p18007398/s50340409/3eeeb2ac-9bca9174-549fbb9e-0dad8292-81377269.jpg
study_id 50340409 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p18/p18007398/s50340409/3eeeb2ac-9bca9174-549fbb9e-0dad8292-81377269.jpg ground_truth The patient is intubated, the tip of the endotracheal tube projects 4 cm above the carina. To right and 1 left-sided chest tube are in place. Nasogastric tube shows a normal course. Left retrocardiac atelectasis. Minimal right pleural effusion. No visible pneumothorax. Non displaced rib fractures described on the ct examination from ___, 19:33, are not visualized on the radiograph. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p19/p19366448/s50411452/da94e05c-941be1ba-f5996c0b-75dd288f-278d8503.jpg
study_id 50411452 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p19/p19366448/s50411452/da94e05c-941be1ba-f5996c0b-75dd288f-278d8503.jpg ground_truth There are low lung volumes. Cardiac size is top-normal accentuated by the projection of the low lung volumes. Lines and tubes are in unchanged standard position. There is mild vascular congestion. Increasing bibasilar opacities are likely atelectasis. Atelectasis in the perihilar regions bilaterally are unchanged prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p10/p10522265/s50421811/d5aedb5c-3e300b8e-4ab8aa68-066f67dc-cfe7bd84.jpg
study_id 50421811 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p10/p10522265/s50421811/d5aedb5c-3e300b8e-4ab8aa68-066f67dc-cfe7bd84.jpg ground_truth Mild to moderate pulmonary edema, with a basal predominance, is new probably accompanied by small pleural effusions. Heart size is top-normal not appreciably changed. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p19/p19598137/s50422579/c5157006-1a73eeaf-efe1fd1c-7c18314b-7183f206.jpg
study_id 50422579 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p19/p19598137/s50422579/c5157006-1a73eeaf-efe1fd1c-7c18314b-7183f206.jpg ground_truth Exam is limited by significant rotation. Heart size is enlarged. The mediastinal and hilar contours are normal. The pulmonary vasculature is normal. Lungs are clear. No pleural effusion or pneumothorax is seen. There are no acute osseous abnormalities. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p16/p16768418/s50484024/695acea4-7d4be71d-9243cd6c-c90f68cc-cf5d3a75.jpg
study_id 50484024 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p16/p16768418/s50484024/695acea4-7d4be71d-9243cd6c-c90f68cc-cf5d3a75.jpg ground_truth Ap view of the chest. The lungs are clear. Cardiomediastinal silhouette is within normal limits. No acute osseous abnormality detected. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p13/p13171410/s50557253/58597ddf-5c95d260-4911eef3-5907f696-f132c629.jpg
study_id 50557253 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p13/p13171410/s50557253/58597ddf-5c95d260-4911eef3-5907f696-f132c629.jpg ground_truth There is expected mild postoperative cardiomediastinal silhouette widening. There is mild left basilar atelectasis. No large effusion, pneumothorax or consolidation. Mild pulmonary vascular congestion, without edema. An endotracheal tube tip terminates approximately 5 cm above the carina. A swan-ganz catheter terminates in the right main pulmonary artery. prediction The patient is status post median sternotomy and cabg. The heart is mildly enlarged. The mediastinal and hilar contours are unremarkable. There is no pleural effusion or pneumothorax. The lungs are clear.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p13/p13196707/s50564703/1ad7b193-ec7866e0-b028d0ab-58e2fd05-8da28ddd.jpg
study_id 50564703 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p13/p13196707/s50564703/1ad7b193-ec7866e0-b028d0ab-58e2fd05-8da28ddd.jpg ground_truth 2 catheters are seen projecting over the inferior aspect of the heart. There is a right sided central venous line with the distal lead tip at the cavoatrial junction. Svc stent is also seen. There are low lung volumes due to poor inspiratory effort. There is some elevation of the left hemidiaphragm. There is again seen numerous parenchymal nodules better assessed on the prior ct scan. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17257394/s50572758/d6f297e0-277785b9-0dade959-c098d1a4-1d5c202a.jpg
study_id 50572758 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p17/p17257394/s50572758/d6f297e0-277785b9-0dade959-c098d1a4-1d5c202a.jpg ground_truth Heart size is normal with mild tortuosity of thoracic aorta. Hilar contours are unremarkable. Lungs are clear. Pleural surfaces are clear without large effusion or pneumothorax. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p15/p15902493/s50591741/41cd0cf2-1993dfdd-7f6bf2e5-a1f49826-59bd4a84.jpg
study_id 50591741 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p15/p15902493/s50591741/41cd0cf2-1993dfdd-7f6bf2e5-a1f49826-59bd4a84.jpg ground_truth A tracheostomy catheter appears in standard unchanged position. A catheter overlying the right mid clavicular line appears similar to prior examination, possibly a vp shunt. Elevation of the right hemidiaphragm is unchanged from prior. Linear bibasilar opacities are unchanged and likely reflect atelectasis. No confluent consolidation is identified. A significant widening of the right paratracheal stripe corresponds with a known large thyroid goiter, better characterized on prior chest ct. Leftward tracheal deviation appears stable. The remainder of the mediastinal and hilar contours are within normal limits for age. The heart size is borderline or slightly enlarged. There is pneumothorax. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11307058/s50677909/9f2507a2-f8ed6c9f-657277ba-664fb54d-c23684b6.jpg
study_id 50677909 prompt The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
<image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11307058/s50677909/9f2507a2-f8ed6c9f-657277ba-664fb54d-c23684b6.jpg ground_truth Up several lines are projecting over the chest, most of them are external except for central venous line terminating in the level of lower svc. Heart size is unchanged, normal in size. Severely dilated and tortuous descending thoracic aorta is consistent with known aneurysm i tip dissection. Lungs are essentially clear with no evidence of focal consolidation to suggest infectious process prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax. The visualized osseous structures are unremarkable.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p10/p10649970/s50701407/a1c8c7ce-7da30482-9513e5d6-e9c94ca0-4ce8696a.jpg
study_id 50701407 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p10/p10649970/s50701407/a1c8c7ce-7da30482-9513e5d6-e9c94ca0-4ce8696a.jpg ground_truth Lung volumes remain somewhat low. There are multiple small calcified nodular opacities in the right mid and lower lungs, which are unchanged. No pulmonary edema or airspace consolidation to suggest an acute infectious process. No pneumothorax or pleural effusions. Overall cardiac and mediastinal contours are stable. No pneumothorax. prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax.
image_url: /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11888614/s50703372/65a8e3b5-8552ea89-9bc2e215-fd42bed9-e469687f.jpg
study_id 50703372 prompt <image>
Analyze the Chest X-ray image above and provide your findings. image /home/r11kaijun/physionet.org/files/mimic-cxr-jpg/2.1.0/files/p11/p11888614/s50703372/65a8e3b5-8552ea89-9bc2e215-fd42bed9-e469687f.jpg ground_truth Et tube tip is 3 cm above the carinal. Ng tube tip is in the stomach. Pulmonary edema is substantial, bilateral associated with large bilateral pleural effusions. No evidence of pneumothorax expressed prediction The lungs are clear. The cardiomediastinal silhouette and hilar contours are normal. There is no pleural effusion or pneumothorax.
